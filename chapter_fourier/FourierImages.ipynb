{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ssec:fou-image)=\n",
    "## Image processing using the Fast Fourier Transform\n",
    "\n",
    "In this section, we have a glance at how the Fast Fourier Transform (FFT) can be used to process images. The FFT is a powerful tool for analyzing the frequency content of signals, including images. By transforming an image into the frequency domain, we can manipulate its frequency components to achieve various effects, such as filtering, compression, and enhancement.\n",
    "\n",
    "The examples below are taken and adapted from {cite}`BruntonKutz2022`, Chapter 2.2.\n",
    "which the authors of the book kindly made available on [GitHub](https://github.com/dynamicslab/databook_python), see in particular the examples \n",
    "[CH02_SEC06_2_Compress.ipynb](https://github.com/dynamicslab/databook_python/blob/master/CH02/CH02_SEC06_2_Compress.ipynb)\n",
    "and\n",
    "[CH02_SEC06_3_Denoise.ipynb](https://github.com/dynamicslab/databook_python/blob/master/CH02/CH02_SEC06_3_Denoise.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "thebe-init",
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from scipy.fft import fft2, ifft2, fftfreq, fftshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load images stored in jpeg or png format directly from the filesystem using the `imread` function from `matplotlib.image`. \n",
    "This function takes the path to the image file as an argument and returns a NumPy array representing the image.\n",
    "\n",
    "When a color image is loaded, the resulting array has three dimensions: \n",
    "* **height**: the number of pixel rows in the image\n",
    "* **width**: the number of pixel columns in the image\n",
    "* **color**: channels: the number of color channels (3 for RGB images)\n",
    "\n",
    "![Images as 3D array](color_image_array.png)\n",
    "\n",
    "\n",
    "For digital images using the Red-Green-Blue (RGB) color model,\n",
    "the color of a single pixel is represented by a vector like [R, G, B], \n",
    "where R, G, and B are typically integers in the range [0, 255]:\n",
    "\n",
    "* R = Red intensity\n",
    "* G = Green intensity\n",
    "* B = Blue intensity\n",
    "\n",
    "Each component is typically an integer between 0 and 255 (8-bit unsigned integer), where:\n",
    "* 0 means no intensity of that color\n",
    "* 255 means maximum intensity\n",
    "\n",
    "The final color seen at that pixel is a mix of the red, green, and blue light in the specified intensities.\n",
    "\n",
    "Examples:\n",
    "* [255, 0, 0] → Pure Red\n",
    "* [0, 255, 0] → Pure Green\n",
    "* [0, 0, 255] → Pure Blue\n",
    "* [255, 255, 255] → White (full intensity of all colors)\n",
    "* [0, 0, 0] → Black (no color/light)\n",
    "* [128, 128, 128] → Gray (equal parts of R, G, B)\n",
    "\n",
    "For grayscale images, the array has two dimensions (height, width), with each pixel represented by a single intensity value ranging from 0 (black) to 255 (white)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load an image using the `imread` function from\n",
    "`matplotlib.image` submodule and display it using\n",
    "`matplotlib.pyplot.imshow` function, once as original image and then\n",
    "with only one channel activated at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogimage = imread('dog.jpg').copy()\n",
    "print(dogimage.shape)\n",
    "print(dogimage.min())\n",
    "print(dogimage.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "ax[0,0].imshow(dogimage, cmap='gray')\n",
    "\n",
    "dogimage_red = dogimage.copy()\n",
    "dogimage_red[:, :, [1,2]] = 0\n",
    "ax[0,1].imshow(dogimage_red)\n",
    "\n",
    "dogimage_green = dogimage.copy()\n",
    "dogimage_green[:, :, [0,2]] = 0\n",
    "ax[1,0].imshow(dogimage_green)\n",
    "\n",
    "dogimage_blue = dogimage.copy()\n",
    "dogimage_blue[:, :, [0,1]] = 0\n",
    "ax[1,1].imshow(dogimage_blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "# ax[0,0].imshow(dogimage)\n",
    "\n",
    "# ax[0,1].imshow(dogimage[:,:,0])\n",
    "# ax[1,0].imshow(dogimage[:,:,1])\n",
    "# ax[1,1].imshow(dogimage[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we turn the image into a gray scale image by simply taking the average of the three channels. This results in a 2D array of shape (height, width) instead of a 3D array of shape (height, width, 3). The resulting image is a gray scale image where each pixel is represented by a single value between 0 and 255. The value 0 represents black and the value 255 represents white. The values in between represent different shades of gray.\n",
    "\n",
    "When you plotting the image, you must tell `imshow` that the image is gray scale by passing the `cmap` argument with the value `gray`. The `cmap` argument is short for color map. The default value is `viridis`, which is a color map that is perceptually uniform and works well for most applications. However, when displaying gray scale images, we want to use a different color map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggray = np.mean(dogimage, axis=2)\n",
    "plt.imshow(doggray, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compressing grayscale images using the FFT\n",
    "Let us illustrate how to use the FFT to compress a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doggray_hat = fft2(doggray)\n",
    "# Sort by magnitude to determine the most significant frequencies\n",
    "doggray_hat_sort = np.sort(np.abs(doggray_hat.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero out all small coefficients and inverse transform\n",
    "import math\n",
    "keep_ratios  = (1.0, 0.1, 0.05, 0.01, 0.002)\n",
    "for i in range(len(keep_ratios)):\n",
    "    keep = keep_ratios[i]\n",
    "    thresh = doggray_hat_sort[int(np.floor((1-keep)*len(doggray_hat_sort)))]\n",
    "    ind = np.abs(doggray_hat)>thresh          # Find small indices\n",
    "    Atlow = doggray_hat * ind                 # Threshold small indices\n",
    "    Alow = np.fft.ifft2(Atlow).real  # Compressed image\n",
    "    plt.figure()\n",
    "    plt.imshow(Alow,cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.title('Compressed image: keep = ' + str(keep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple denoising example using the FFT\n",
    "\n",
    "We illustrate how to use the FFT to denoise a grayscale image.\n",
    "First, we add some noise to the image. The noise is generated using a standard normal distribution with a mean of 0 and variance of 1. \n",
    "The noise is then added to the original image, resulting in a noisy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.mean(dogimage, -1); # Convert RGB to grayscale\n",
    "\n",
    "## Add some noise\n",
    "Bnoise = B + 200*np.random.randn(*B.shape).astype('uint8') # Add some noise\n",
    "fig,axs = plt.subplots(1,2,figsize=(16,16))\n",
    "axs[0].imshow(B,cmap='gray')\n",
    "axs[0].set_title('Original image')\n",
    "axs[1].imshow(Bnoise,cmap='gray')\n",
    "axs[1].set_title('Noisy image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to see how their respective Fourier transforms look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bhat_shift = fftshift(fft2(B)) # FFT of noisy image\n",
    "Bnoisehat_shift = fftshift(fft2(Bnoise)) # FFT of noisy image\n",
    "ny,nx = B.shape\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(16,16))\n",
    "img0 = axs[0].imshow(np.abs(Bhat_shift),cmap='gray',\n",
    "                     extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "axs[0].set_title('Original image')\n",
    "fig.colorbar(img0, orientation='vertical', shrink=0.5)\n",
    "\n",
    "img1 = axs[1].imshow(np.abs(Bnoisehat_shift),cmap='gray',\n",
    "                        extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "axs[1].set_title('Noisy image')\n",
    "fig.colorbar(img1, orientation='vertical', shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was not very helpful! Indeed, large parts of the image's information are concentrated in low frequencies, which are hard to see on a linear scale. Using a logarithmic scale makes low frequencies more visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_Bhat_shift = np.log(1 + np.abs(Bhat_shift))\n",
    "log_Bnoisehat_shift = np.log(1 + np.abs(Bnoisehat_shift))\n",
    "ny,nx = B.shape\n",
    "\n",
    "fig,axs = plt.subplots(1,2,figsize=(16,16))\n",
    "img0 = axs[0].imshow(log_Bhat_shift,cmap='gray',\n",
    "                     extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "axs[0].set_title('Original image')\n",
    "# axs[0].axis('off')\n",
    "fig.colorbar(img0, orientation='vertical', shrink=0.5)\n",
    "\n",
    "img1 = axs[1].imshow(log_Bnoisehat_shift,cmap='gray',\n",
    "                     extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "axs[1].set_title('Noisy image')\n",
    "# axs[1].axis('off')\n",
    "fig.colorbar(img1, orientation='vertical', shrink=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that most of the information  is concentrated in the low frequencies,\n",
    "as their amplitudes are significantly larger than those of the high frequencies.\n",
    "We also see that adding noise to the image has added high frequency components to the Fourier transform.\n",
    "A simple filtering technique is to remove the high frequency components from the Fourier transform of the noisy image by using a threshold frequency, thus zeroing out the high frequencies.\n",
    "\n",
    "In the code below, we simply neglect all gradients above a certain threshold frequency $f_{\\mathrm{tres}} = 150$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.mean(dogimage, -1); # Convert RGB to grayscale\n",
    "\n",
    "## Denoise\n",
    "Bnoise = B + 200*np.random.randn(*B.shape).astype('uint8') # Add some noise\n",
    "Bt = np.fft.fft2(Bnoise)\n",
    "Btshift = np.fft.fftshift(Bt)\n",
    "\n",
    "F = np.log(np.abs(Btshift)+1) # Put FFT on log scale\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(16,16))\n",
    "\n",
    "axs[0,0].imshow(Bnoise,cmap='gray')\n",
    "axs[0,0].axis('off')\n",
    "\n",
    "axs[0,1].imshow(F,cmap='gray',\n",
    "                     extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "\n",
    "ny,nx = B.shape\n",
    "X,Y = np.meshgrid(np.arange(-nx/2+1,nx/2+1),np.arange(-ny/2+1,ny/2+1))\n",
    "# xgrid = np.fft.ifftshift(np.arange(-nx/2+1,nx/2+1))\n",
    "# ygrid = np.fft.ifftshift(np.arange(-ny/2+1,ny/2+1))\n",
    "# X,Y = np.meshgrid(ygrid,xgrid)\n",
    "R2 = np.power(X,2) + np.power(Y,2)\n",
    "ind = R2 < 150**2\n",
    "Btshiftfilt = Btshift * ind\n",
    "Ffilt = np.log(np.abs(Btshiftfilt)+1) # Put FFT on log scale\n",
    "\n",
    "axs[1,1].imshow(Ffilt,cmap='gray',\n",
    "                     extent=(-nx/2,nx/2,-ny/2,ny/2))\n",
    "\n",
    "Btfilt = np.fft.ifftshift(Btshiftfilt)\n",
    "Bfilt = np.fft.ifft2(Btfilt).real\n",
    "axs[1,0].imshow(Bfilt,cmap='gray')\n",
    "axs[1,0].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{prf:remark}\n",
    "We want to stress that the shown examples/techniques are quite simplistic and  mainly presented for educational purposes, that is, to give you an idea where/how the FFT can be used in image processing.\n",
    "Of course, there are many, many more sophisticated techniques for image compression and denoising, such as windowed Fourier transform,  wavelet transforms, principal component analysis (PCA), and deep learning-based methods which we cannot cover here,\n",
    "see ee.g. {cite}`BruntonKutz2022`, and references therein.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tma4320_scientific_computation-vlMPykwy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
